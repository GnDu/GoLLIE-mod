{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7364c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# cd to ../src\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a42799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.load_model import load_model_for_inference\n",
    "import random\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerBase,\n",
    ")\n",
    "from transformers.modeling_utils import unwrap_model\n",
    "from transformers.models.auto.modeling_auto import MODEL_FOR_CAUSAL_LM_MAPPING_NAMES\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e1ed1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Device map: auto\n",
      "INFO:root:Loading model from /gaueko1/hizkuntza-ereduak/LLaMA/lm/huggingface/7B/\n",
      "WARNING:root:Model /gaueko1/hizkuntza-ereduak/LLaMA/lm/huggingface/7B/ is an encoder-only model. We will load it as a CausalLM model.\n",
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda-11.7/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /ikerlariak/igarcia945/envs/pytorch2/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ikerlariak/igarcia945/envs/pytorch2/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/lib/boost-1.46.1'), PosixPath('/usr/local/boost/lib')}\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708feb3036c04b38916c598d6ea00ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model does not have a pad token, we will use the unk token as pad token.\n",
      "INFO:root:Loading pretrained LORA weights from /ikerlariak/osainz006/models/collie/CoLLIE-7b\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model_for_inference(\n",
    "    weights_path=\"/gaueko1/hizkuntza-ereduak/LLaMA/lm/huggingface/7B/\",\n",
    "    int8_quantization=True,\n",
    "    lora_weights_name_or_path=\"/ikerlariak/osainz006/models/collie/CoLLIE-7b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59ef006a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The following lines describe the task definition\n",
      "@dataclass\n",
      "class Person(Entity):\n",
      "    \"\"\"Persons: first, middle and last names of people, animals and fictional\n",
      "            characters\n",
      "    aliases\"\"\"\n",
      "\n",
      "    span: str\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Organization(Entity):\n",
      "    \"\"\"Organizations: companies (press agencies, studios, banks, stock\n",
      "               markets, manufacturers, cooperatives)\n",
      "    subdivisions of companies (newsrooms)\n",
      "    brands\n",
      "    political movements (political parties, terrorist\n",
      "              organisations)\n",
      "    government bodies (ministries, councils, courts, political unions\n",
      "               of countries (e.g. the {\\\\it U.N.}))\n",
      "    publications (magazines, newspapers, journals)\n",
      "    musical companies (bands, choirs, opera companies, orchestras\n",
      "    public organisations (schools, universities, charities\n",
      "    other collections of people (sports clubs, sports\n",
      "              teams, associations, theaters companies,\n",
      "              religious orders, youth organisations\n",
      "    \"\"\"\n",
      "\n",
      "    span: str\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Location(Entity):\n",
      "    \"\"\"Locations: roads (streets, motorways)\n",
      "    trajectories\n",
      "    regions (villages, towns, cities, provinces, countries, continents,\n",
      "             dioceses, parishes)\n",
      "    structures (bridges, ports, dams)\n",
      "    natural locations (mountains, mountain ranges, woods,\n",
      "                       rivers, wells, fields, valleys, gardens,\n",
      "                       nature reserves, allotments, beaches,\n",
      "                       national parks)\n",
      "    public places (squares, opera houses, museums, schools,\n",
      "                   markets, airports, stations, swimming pools,\n",
      "                   hospitals, sports facilities, youth centers,\n",
      "                   parks, town halls, theaters, cinemas, galleries,\n",
      "                   camping grounds, NASA launch pads, club\n",
      "                   houses, universities, libraries, churches,\n",
      "                   medical centers, parking lots, playgrounds,\n",
      "                   cemeteries)\n",
      "    commercial places (chemists, pubs, restaurants, depots,\n",
      "                       hostels, hotels, industrial parks,\n",
      "                       nightclubs, music venues)\n",
      "    assorted buildings (houses, monasteries, creches, mills,\n",
      "                        army barracks, castles, retirement\n",
      "                        homes, towers, halls, rooms, vicarages,\n",
      "                        courtyards)\n",
      "    abstract ``places'' (e.g. {\\\\it the free world})\n",
      "    \"\"\"\n",
      "\n",
      "    span: str\n",
      "\n",
      "\n",
      "# This is the text to analyze\n",
      "text = \"In any event , this question is not presently included among the requests for topical and urgent debate on Thursday .\"\n",
      "\n",
      "# The annotation instances that take place in the text above are listed here\n",
      "result = [\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    '# The following lines describe the task definition\\n@dataclass\\nclass Person(Entity):\\n    \"\"\"Persons: first,'\n",
    "    ' middle and last names of people, animals and fictional\\n            characters\\n    aliases\"\"\"\\n\\n    span:'\n",
    "    ' str\\n\\n\\n@dataclass\\nclass Organization(Entity):\\n    \"\"\"Organizations: companies (press agencies, studios,'\n",
    "    \" banks, stock\\n               markets, manufacturers, cooperatives)\\n    subdivisions of companies (newsrooms)\\n \"\n",
    "    \"   brands\\n    political movements (political parties, terrorist\\n              organisations)\\n    government\"\n",
    "    \" bodies (ministries, councils, courts, political unions\\n               of countries (e.g. the {\\\\\\\\it U.N.}))\\n \"\n",
    "    \"   publications (magazines, newspapers, journals)\\n    musical companies (bands, choirs, opera companies,\"\n",
    "    \" orchestras\\n    public organisations (schools, universities, charities\\n    other collections of people (sports\"\n",
    "    \" clubs, sports\\n              teams, associations, theaters companies,\\n              religious orders, youth\"\n",
    "    ' organisations\\n    \"\"\"\\n\\n    span: str\\n\\n\\n@dataclass\\nclass Location(Entity):\\n    \"\"\"Locations: roads'\n",
    "    \" (streets, motorways)\\n    trajectories\\n    regions (villages, towns, cities, provinces, countries,\"\n",
    "    \" continents,\\n             dioceses, parishes)\\n    structures (bridges, ports, dams)\\n    natural locations\"\n",
    "    \" (mountains, mountain ranges, woods,\\n                       rivers, wells, fields, valleys, gardens,\\n          \"\n",
    "    \"             nature reserves, allotments, beaches,\\n                       national parks)\\n    public places\"\n",
    "    \" (squares, opera houses, museums, schools,\\n                   markets, airports, stations, swimming pools,\\n    \"\n",
    "    \"               hospitals, sports facilities, youth centers,\\n                   parks, town halls, theaters,\"\n",
    "    \" cinemas, galleries,\\n                   camping grounds, NASA launch pads, club\\n                   houses,\"\n",
    "    \" universities, libraries, churches,\\n                   medical centers, parking lots, playgrounds,\\n            \"\n",
    "    \"       cemeteries)\\n    commercial places (chemists, pubs, restaurants, depots,\\n                       hostels,\"\n",
    "    \" hotels, industrial parks,\\n                       nightclubs, music venues)\\n    assorted buildings (houses,\"\n",
    "    \" monasteries, creches, mills,\\n                        army barracks, castles, retirement\\n                      \"\n",
    "    \"  homes, towers, halls, rooms, vicarages,\\n                        courtyards)\\n    abstract ``places'' (e.g.\"\n",
    "    ' {\\\\\\\\it the free world})\\n    \"\"\"\\n\\n    span: str\\n\\n\\n# This is the text to analyze\\ntext = \"In any event ,'\n",
    "    ' this question is not presently included among the requests for topical and urgent debate on Thursday .\"\\n\\n# The'\n",
    "    \" annotation instances that take place in the text above are listed here\\nresult = [\"\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "407d4e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,   396,   450,  1494,  3454,  8453,   278,  3414,  5023,    13,\n",
       "         29992,  1272,  1990,    13,  1990,  5196, 29898,  6691,  1125,    13,\n",
       "          1678,  9995, 15136,   787, 29901,   937, 29892,  7256,   322,  1833,\n",
       "          2983,   310,  2305, 29892, 15006,   322, 26797,  1848,    13,  9651,\n",
       "          4890,    13,  1678, 14430,  2129, 15945, 29908,    13,    13,  1678,\n",
       "         10638, 29901,   851,    13,    13,    13, 29992,  1272,  1990,    13,\n",
       "          1990,  9205,  2133, 29898,  6691,  1125,    13,  1678,  9995, 27356,\n",
       "         17063, 29901, 14582,   313,  2139,   946, 15942, 29892,  1921,  2363,\n",
       "         29892, 24388, 29892, 10961,    13,  1669,  2791,  1691, 29892, 12012,\n",
       "           332,   414, 29892,  1302,  3372,  5056, 29897,    13,  1678,  1014,\n",
       "          4563, 12112,   310, 14582,   313, 15753, 18901, 29897,    13,  1678,\n",
       "          1506,  4167,    13,  1678,  8604, 24147,   313, 20087,   936, 13973,\n",
       "         29892, 15115,   391,    13,   795, 17459,   800, 29897,    13,  1678,\n",
       "          5874, 17873,   313,  1195,   391,  2722, 29892,  2613, 29883,  2719,\n",
       "         29892, 28033, 29892,  8604,   443,  1080,    13,  1669,   310, 10916,\n",
       "           313, 29872, 29889, 29887, 29889,   278,   426,  1966,   277,   501,\n",
       "         29889, 29940,  5003,   876,    13,  1678, 25964,   313, 11082,   834,\n",
       "          1475, 29892, 14578, 21321, 29892, 21824,  1338, 29897,    13,  1678,\n",
       "          9636, 14582,   313, 29890,  4167, 29892,  3060, 12935, 29892, 14495,\n",
       "         14582, 29892, 22624,   342,  3417,    13,  1678,   970, 17459,   800,\n",
       "           313,   816,  8789, 29892,  4946,  1907, 29892,  1373,  1907,    13,\n",
       "          1678,   916, 16250,   310,  2305,   313, 29879,  4011, 17651, 29892,\n",
       "         14717,    13,   795, 10907, 29892, 27733, 29892,   278, 10412, 14582,\n",
       "         29892,    13,   795, 12962, 11299, 29892, 12397, 17459,   800,    13,\n",
       "          1678,  9995,    13,    13,  1678, 10638, 29901,   851,    13,    13,\n",
       "            13, 29992,  1272,  1990,    13,  1990, 17015, 29898,  6691,  1125,\n",
       "            13,  1678,  9995,  3524,   800, 29901, 25320,   313, 13045,  1691,\n",
       "         29892, 10992,  1994, 29897,    13,  1678, 23324,  3842,    13,  1678,\n",
       "         12786,   313, 29894,   453,  1179, 29892, 20248, 29892, 14368, 29892,\n",
       "         28058, 29892, 10916, 29892,  2145,  1237, 29892,    13,   632, 22386,\n",
       "         21523, 29892,   610, 17006, 29897,    13,  1678, 12286,   313, 19515,\n",
       "          2710, 29892, 16169, 29892,   270,  2232, 29897,    13,  1678,  5613,\n",
       "         14354,   313, 16476,  2708, 29892, 14378, 20238, 29892, 25013, 29892,\n",
       "            13,   462,   539, 27515, 29892,  1532, 29879, 29892,  4235, 29892,\n",
       "         28519,   952, 29892, 17161,   575, 29892,    13,   462,   539,  5469,\n",
       "           620, 20098, 29892,   599,   327,  1860, 29892,   367, 14520, 29892,\n",
       "            13,   462,   539,  4797,   610,  2039, 29897,    13,  1678,   970,\n",
       "          7600,   313, 26613,  5114, 29892, 14495, 12955, 29892, 19133, 29879,\n",
       "         29892, 12462, 29892,    13,   462,   259,  2791,  1691, 29892,  4799,\n",
       "          4011, 29892, 16355, 29892,  2381, 25217,   772,  3775, 29892,    13,\n",
       "           462,   259, 29418,   277,  1338, 29892, 14717, 23330, 29892, 12397,\n",
       "          1644,   414, 29892,    13,   462,   259,   610,  2039, 29892,  4726,\n",
       "           298,  4293, 29892,   278, 10412, 29892,  4670,  8609, 29892, 11798,\n",
       "          6358, 29892,    13,   462,   259,  4242,   292, 25502, 29892, 24206,\n",
       "          6826,   282,  7925, 29892,  4402,    13,   462,   259, 12955, 29892,\n",
       "          4946,  1907, 29892,  9562, 29892, 26014, 29892,    13,   462,   259,\n",
       "         16083,  1644,   414, 29892,   610,  9292, 14568, 29892,  1708,  2057,\n",
       "         29879, 29892,    13,   462,   259,   274,   331,  1308,   583, 29897,\n",
       "            13,  1678, 12128,  7600,   313, 14969,  2879, 29892,  2529, 29879,\n",
       "         29892, 12374,  1934, 29892,  1401,  1862, 29892,    13,   462,   539,\n",
       "          3495,  1379, 29892,  7375,  1379, 29892, 18408,   610,  2039, 29892,\n",
       "            13,   462,   539,  4646,   695, 23954, 29892,  4696,  6003,  1041,\n",
       "         29897,    13,  1678,  1223, 18054, 13814,   313, 29882, 23676, 29892,\n",
       "         23937,   583, 29892,   907,  6609, 29892,  3533, 29879, 29892,    13,\n",
       "           462,  4706,  9987,  2594,   336,  4684, 29892,  4320,   793, 29892,\n",
       "          3240, 19211,    13,   462,  4706, 17774, 29892,   304, 17538, 29892,\n",
       "           298,  4293, 29892, 19600, 29892,  9467,   279,  1179, 29892,    13,\n",
       "           462,  4706,  2085,  1017,  3163, 29897,    13,  1678,  9846,  4954,\n",
       "         29886,  6048,  4907,   313, 29872, 29889, 29887, 29889,   426,  1966,\n",
       "           277,   278,  3889,  3186,  1800,    13,  1678,  9995,    13,    13,\n",
       "          1678, 10638, 29901,   851,    13,    13,    13, 29937,   910,   338,\n",
       "           278,  1426,   304, 27599,    13,   726,   353,   376,   797,   738,\n",
       "          1741,  1919,   445,  1139,   338,   451, 28681,  5134,  4249,   278,\n",
       "          7274,   363,  2246,   936,   322,  5065,  5362, 27836,   373,   498,\n",
       "          1295,  3250,   869, 29908,    13,    13, 29937,   450, 17195,  8871,\n",
       "           393,  2125,  2058,   297,   278,  1426,  2038,   526,  9904,  1244,\n",
       "            13,  2914,   353,   518]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = tokenizer(prompt, add_special_tokens=True, return_tensors=\"pt\")\n",
    "model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be2b590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ouput = model.generate(input_ids=model_input.input_ids.to(model.device), max_new_tokens=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82ea1aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> # The following lines describe the task definition\n",
      "@dataclass\n",
      "class Person(Entity):\n",
      "    \"\"\"Persons: first, middle and last names of people, animals and fictional\n",
      "            characters\n",
      "    aliases\"\"\"\n",
      "\n",
      "    span: str\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Organization(Entity):\n",
      "    \"\"\"Organizations: companies (press agencies, studios, banks, stock\n",
      "               markets, manufacturers, cooperatives)\n",
      "    subdivisions of companies (newsrooms)\n",
      "    brands\n",
      "    political movements (political parties, terrorist\n",
      "              organisations)\n",
      "    government bodies (ministries, councils, courts, political unions\n",
      "               of countries (e.g. the {\\\\it U.N.}))\n",
      "    publications (magazines, newspapers, journals)\n",
      "    musical companies (bands, choirs, opera companies, orchestras\n",
      "    public organisations (schools, universities, charities\n",
      "    other collections of people (sports clubs, sports\n",
      "              teams, associations, theaters companies,\n",
      "              religious orders, youth organisations\n",
      "    \"\"\"\n",
      "\n",
      "    span: str\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Location(Entity):\n",
      "    \"\"\"Locations: roads (streets, motorways)\n",
      "    trajectories\n",
      "    regions (villages, towns, cities, provinces, countries, continents,\n",
      "             dioceses, parishes)\n",
      "    structures (bridges, ports, dams)\n",
      "    natural locations (mountains, mountain ranges, woods,\n",
      "                       rivers, wells, fields, valleys, gardens,\n",
      "                       nature reserves, allotments, beaches,\n",
      "                       national parks)\n",
      "    public places (squares, opera houses, museums, schools,\n",
      "                   markets, airports, stations, swimming pools,\n",
      "                   hospitals, sports facilities, youth centers,\n",
      "                   parks, town halls, theaters, cinemas, galleries,\n",
      "                   camping grounds, NASA launch pads, club\n",
      "                   houses, universities, libraries, churches,\n",
      "                   medical centers, parking lots, playgrounds,\n",
      "                   cemeteries)\n",
      "    commercial places (chemists, pubs, restaurants, depots,\n",
      "                       hostels, hotels, industrial parks,\n",
      "                       nightclubs, music venues)\n",
      "    assorted buildings (houses, monasteries, creches, mills,\n",
      "                        army barracks, castles, retirement\n",
      "                        homes, towers, halls, rooms, vicarages,\n",
      "                        courtyards)\n",
      "    abstract ``places'' (e.g. {\\\\it the free world})\n",
      "    \"\"\"\n",
      "\n",
      "    span: str\n",
      "\n",
      "\n",
      "# This is the text to analyze\n",
      "text = \"In any event , this question is not presently included among the requests for topical and urgent debate on Thursday .\"\n",
      "\n",
      "# The annotation instances that take place in the text above are listed here\n",
      "result = [\n",
      "    Person(span=\"Thursday\"),\n",
      "]\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(model_ouput)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce034e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa879e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1121, 353, 5159]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"result = []\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ef0034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1121, 353, 518]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"result = [\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bc20d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1121, 353, 29961]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"result =[\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cb163f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1121, 353]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"result =\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3ee876b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1121, 353, 518]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"result = [\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abecf54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 518, 4514]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"[ ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fe95836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 29871, 29947, 25512, 29928]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"8===D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d33839d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':=',\n",
       " '▁===',\n",
       " '▁=~',\n",
       " '=\".',\n",
       " '=\"$',\n",
       " '▁<=',\n",
       " '▁!==',\n",
       " '=\\\\{',\n",
       " '<%=',\n",
       " '=\\\\',\n",
       " '}=\\\\',\n",
       " \"='\",\n",
       " '▁==>',\n",
       " '=`',\n",
       " '▁<%=',\n",
       " '▁&=\\\\',\n",
       " '={{',\n",
       " '>=',\n",
       " '\"=>',\n",
       " \"'=>\",\n",
       " ')=',\n",
       " '=\"/',\n",
       " '▁=>',\n",
       " '▁=',\n",
       " '=/',\n",
       " '▁.=',\n",
       " '.=',\n",
       " '=\"\"',\n",
       " '&=',\n",
       " '▁+=',\n",
       " '=-',\n",
       " '+=',\n",
       " '<=',\n",
       " '=$(',\n",
       " '=${',\n",
       " '=\"${',\n",
       " '▁-=',\n",
       " '%=',\n",
       " '====',\n",
       " '={',\n",
       " '=\"#',\n",
       " '=\"{',\n",
       " ']=',\n",
       " '}}=',\n",
       " '}=',\n",
       " ']=\"',\n",
       " '==\"',\n",
       " '========',\n",
       " '▁>=',\n",
       " '▁!=',\n",
       " '▁==',\n",
       " '=.',\n",
       " '▁:=',\n",
       " '▁(=',\n",
       " '================',\n",
       " '!=',\n",
       " '===',\n",
       " '=>',\n",
       " '=&',\n",
       " '=(',\n",
       " '▁=\"',\n",
       " '▁=\\\\',\n",
       " '=\"',\n",
       " '=[',\n",
       " '==',\n",
       " '=\\\\\"',\n",
       " '▁&=',\n",
       " '=\"@',\n",
       " ')=\\\\',\n",
       " '=%',\n",
       " '=$',\n",
       " '=\"@+',\n",
       " '=',\n",
       " '={\\\\',\n",
       " '=\"<?']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in tokenizer.vocab if \"=\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d6d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
