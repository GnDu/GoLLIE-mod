{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2afe3b",
   "metadata": {},
   "source": [
    "<img src=\"../assets/CoLLIE_blue.png\" alt=\"GoLLIE\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003b73a2",
   "metadata": {},
   "source": [
    "# Named Entity Recognition with GoLLIE\n",
    "\n",
    "This notebook is an example of how to run Named Entity Recognition with GoLLIE.  \n",
    "In this example, we will use the CoNLL03 guidelines: https://www.clips.uantwerpen.be/conll2003/ner/\n",
    "\n",
    "You can modify the script to run any Named Entity Recognition task you want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b015c64",
   "metadata": {},
   "source": [
    "### Import requeriments\n",
    "\n",
    "See the requeriments.txt file in the main directory to install the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed51491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # Add the GoLLIE base directory to sys path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "28ff498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from src.model.load_model import load_model\n",
    "import black\n",
    "import inspect\n",
    "from jinja2 import Template\n",
    "import tempfile\n",
    "from src.tasks.utils_typing import AnnotationList\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "from typing import Dict, List, Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004626bb",
   "metadata": {},
   "source": [
    "## Load GoLLIE\n",
    "\n",
    "We will load GoLLIE-7B from the hugginface hub\n",
    "\n",
    "- Set force_auto_device_map=\"auto\" if you want to use the GPU\n",
    "- Set quantization=4 if the model doesn't fit in your GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e6be9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading model model from codellama/CodeLlama-7b-hf\n",
      "INFO:root:We will load the model using the following device map: None and max_memory: None\n",
      "WARNING:root:Tokenizer does not have a pad token, we will use the unk token as pad token.\n",
      "INFO:root:Loading model with dtype: None\n",
      "WARNING:root:Model codellama/CodeLlama-7b-hf is an decoder-only model. We will load it as a CausalLM model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94089d42c5614b28bafeb103c048f29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model dtype: torch.float32\n",
      "INFO:root:Total model memory footprint: 27491.065856 MB\n",
      "INFO:root:Loading pretrained LORA weights from /ikerlariak/osainz006/models/collie/CoLLIE+-7b_CodeLLaMA\n",
      "INFO:root:\n",
      "LoRA config:\n",
      "{'default': LoraConfig(peft_type='LORA', auto_mapping=None, base_model_name_or_path='/gaueko1/hizkuntza-ereduak/Code-LLaMA/huggingface/7b', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=8, target_modules=['gate_proj', 'o_proj', 'down_proj', 'k_proj', 'up_proj', 'v_proj', 'q_proj'], lora_alpha=16, lora_dropout=0.05, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None)}\n",
      "\n",
      "INFO:root:Merging LoRA layers into the model for faster inference.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model(\n",
    "    inference=True,\n",
    "    model_weights_name_or_path=\"codellama/CodeLlama-7b-hf\",\n",
    "    quantization=None,\n",
    "    use_lora=True,\n",
    "    lora_weights_name_or_path=\"/ikerlariak/osainz006/models/collie/CoLLIE+-7b_CodeLLaMA\",\n",
    "    force_auto_device_map=False,\n",
    "    use_flash_attention=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "70e2aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a662bf3",
   "metadata": {},
   "source": [
    "## Define the guideles\n",
    "\n",
    "First, we will define the Labels and guidelines for the task. We define them as Python Classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8520ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from src.tasks.utils_typing import Entity, dataclass\n",
    "\n",
    "\"\"\"Entity definitions\n",
    "\n",
    "The entity definitions are derived from the official ConLL2003 guidelines:\n",
    "https://www.clips.uantwerpen.be/conll2003/ner/\n",
    "Based on: Nancy Chinchor, Erica Brown, Lisa Ferro, Patty Robinson,\n",
    "           \"1999 Named Entity Task Definition\". MITRE and SAIC, 1999.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Person(Entity):\n",
    "    \"\"\"first, middle and last names of people, animals and fictional characters aliases.\"\"\"\n",
    "\n",
    "    span: str  # Such as: \"Clinton\", \"Dole\", \"Arafat\", \"Yeltsin\", \"Lebed\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Organization(Entity):\n",
    "    \"\"\"Companies (press agencies, studios, banks, stock markets, manufacturers, cooperatives) subdivisions of\n",
    "    companies (newsrooms) brands political movements (political parties, terrorist organisations) government bodies\n",
    "    (ministries, councils, courts, political unions of countries (e.g. the {\\it U.N.})) publications (magazines, newspapers,\n",
    "    journals) musical companies (bands, choirs, opera companies, orchestras public organisations (schools, universities,\n",
    "    charities other collections of people (sports clubs, sports teams, associations, theaters companies, religious orders,\n",
    "    youth organisations.\"\"\"\n",
    "\n",
    "    span: str  # Such as: \"Reuters\", \"U.N.\", \"NEW YORK\", \"CHICAGO\", \"PUK\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Location(Entity):\n",
    "    \"\"\"Roads (streets, motorways) trajectories regions (villages, towns, cities, provinces, countries, continents,\n",
    "    dioceses, parishes) structures (bridges, ports, dams) natural locations (mountains, mountain ranges, woods, rivers,\n",
    "    wells, fields, valleys, gardens, nature reserves, allotments, beaches, national parks) public places (squares, opera\n",
    "    houses, museums, schools, markets, airports, stations, swimming pools, hospitals, sports facilities, youth centers,\n",
    "    parks, town halls, theaters, cinemas, galleries, camping grounds, NASA launch pads, club houses, universities,\n",
    "    libraries, churches, medical centers, parking lots, playgrounds, cemeteries) commercial places (chemists, pubs,\n",
    "    restaurants, depots, hostels, hotels, industrial parks, nightclubs, music venues) assorted buildings (houses, monasteries,\n",
    "    creches, mills, army barracks, castles, retirement homes, towers, halls, rooms, vicarages, courtyards) abstract\n",
    "    ``places'' (e.g. {\\it the free world})\"\"\"\n",
    "\n",
    "    span: str  # Such as: \"U.S.\", \"Germany\", \"Britain\", \"Australia\", \"England\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Miscellaneous(Entity):\n",
    "    \"\"\"Words of which one part is a location, organisation, miscellaneous, or person adjectives and other words derived\n",
    "    from a word which is location, organisation, miscellaneous, or person religions political ideologies nationalities\n",
    "    languages programs events (conferences, festivals, sports competitions, forums, parties, concerts) wars sports related\n",
    "    names (league tables, leagues, cups titles (books, songs, films, stories, albums, musicals, TV programs) slogans eras\n",
    "    in time types (not brands) of objects (car types, planes, motorbikes)\"\"\"\n",
    "\n",
    "    span: str  # Such as: \"Russian\", \"German\", \"British\", \"French\", \"Dutch\"\n",
    "\n",
    "\n",
    "ENTITY_DEFINITIONS: List[Entity] = [\n",
    "    Person,\n",
    "    Organization,\n",
    "    Location,\n",
    "    Miscellaneous,\n",
    "]\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    cell_txt = In[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8ef55",
   "metadata": {},
   "source": [
    "### Print the guidelines to guidelines.py\n",
    "\n",
    "Due to IPython limitations, we need to print the content of the previous cell into a file and import the context of the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d4736a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"guidelines.py\",\"w\",encoding=\"utf8\") as python_guidelines:\n",
    "    print(cell_txt,file=python_guidelines)\n",
    "\n",
    "from guidelines import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3db6f",
   "metadata": {},
   "source": [
    "We use inspect.getsource to get the guidelines as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "89454475",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidelines = [inspect.getsource(definition) for definition in ENTITY_DEFINITIONS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bd26b7",
   "metadata": {},
   "source": [
    "## Define input sentence\n",
    "\n",
    "Here we define the input sentence and the gold labels.\n",
    "\n",
    "You can define and empy list as gold labels if you don't have gold annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "db47a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Japan began the defence of their Asian Cup title with a lucky 2-1 win against Syria in a Group C championship match on Friday .\"\n",
    "gold = [Location(span=\"Japan\"),Miscellaneous(span=\"Asian Cup\"),Location(span=\"Syria\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90501322",
   "metadata": {},
   "source": [
    "## Fill the template\n",
    "\n",
    "For NER we will use the following prompt template\n",
    "\n",
    "```Python\n",
    "# The following lines describe the task definition\n",
    "{%- for definition in guidelines %}\n",
    "{{ definition }}\n",
    "{%- endfor %}\n",
    "\n",
    "# This is the text to analyze\n",
    "text = {{ text.__repr__() }}\n",
    "\n",
    "# The annotation instances that take place in the text above are listed here\n",
    "result = [\n",
    "{%- for ann in annotations %}\n",
    "    {{ ann }},\n",
    "{%- endfor %}\n",
    "]\n",
    "\n",
    "```\n",
    "\n",
    "This template is stored in `templates/prompt.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0f54034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../templates/prompt.txt\", \"rt\") as f:\n",
    "    template = Template(f.read())\n",
    "text = template.render(guidelines=guidelines, text=text, annotations=gold, gold=gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886dbc0c",
   "metadata": {},
   "source": [
    "### Black Code Formatter\n",
    "\n",
    "We use the Black Code Formatter to automatically unify all the prompts to the same format. \n",
    "\n",
    "https://github.com/psf/black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c8994924",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_mode = black.Mode()\n",
    "text = black.format_str(text, mode=black_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aa5c0e",
   "metadata": {},
   "source": [
    "### Print the filled and formatted template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fa5f3106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The following lines describe the task definition\n",
      "@dataclass\n",
      "class Person(Entity):\n",
      "    \"\"\"first, middle and last names of people, animals and fictional characters aliases.\"\"\"\n",
      "\n",
      "    span: str  # Such as: \"Clinton\", \"Dole\", \"Arafat\", \"Yeltsin\", \"Lebed\"\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Organization(Entity):\n",
      "    \"\"\"Companies (press agencies, studios, banks, stock markets, manufacturers, cooperatives) subdivisions of\n",
      "    companies (newsrooms) brands political movements (political parties, terrorist organisations) government bodies\n",
      "    (ministries, councils, courts, political unions of countries (e.g. the {\\it U.N.})) publications (magazines, newspapers,\n",
      "    journals) musical companies (bands, choirs, opera companies, orchestras public organisations (schools, universities,\n",
      "    charities other collections of people (sports clubs, sports teams, associations, theaters companies, religious orders,\n",
      "    youth organisations.\"\"\"\n",
      "\n",
      "    span: str  # Such as: \"Reuters\", \"U.N.\", \"NEW YORK\", \"CHICAGO\", \"PUK\"\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Location(Entity):\n",
      "    \"\"\"Roads (streets, motorways) trajectories regions (villages, towns, cities, provinces, countries, continents,\n",
      "    dioceses, parishes) structures (bridges, ports, dams) natural locations (mountains, mountain ranges, woods, rivers,\n",
      "    wells, fields, valleys, gardens, nature reserves, allotments, beaches, national parks) public places (squares, opera\n",
      "    houses, museums, schools, markets, airports, stations, swimming pools, hospitals, sports facilities, youth centers,\n",
      "    parks, town halls, theaters, cinemas, galleries, camping grounds, NASA launch pads, club houses, universities,\n",
      "    libraries, churches, medical centers, parking lots, playgrounds, cemeteries) commercial places (chemists, pubs,\n",
      "    restaurants, depots, hostels, hotels, industrial parks, nightclubs, music venues) assorted buildings (houses, monasteries,\n",
      "    creches, mills, army barracks, castles, retirement homes, towers, halls, rooms, vicarages, courtyards) abstract\n",
      "    ``places'' (e.g. {\\it the free world})\"\"\"\n",
      "\n",
      "    span: str  # Such as: \"U.S.\", \"Germany\", \"Britain\", \"Australia\", \"England\"\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Miscellaneous(Entity):\n",
      "    \"\"\"Words of which one part is a location, organisation, miscellaneous, or person adjectives and other words derived\n",
      "    from a word which is location, organisation, miscellaneous, or person religions political ideologies nationalities\n",
      "    languages programs events (conferences, festivals, sports competitions, forums, parties, concerts) wars sports related\n",
      "    names (league tables, leagues, cups titles (books, songs, films, stories, albums, musicals, TV programs) slogans eras\n",
      "    in time types (not brands) of objects (car types, planes, motorbikes)\"\"\"\n",
      "\n",
      "    span: str  # Such as: \"Russian\", \"German\", \"British\", \"French\", \"Dutch\"\n",
      "\n",
      "\n",
      "# This is the text to analyze\n",
      "text = \"Japan began the defence of their Asian Cup title with a lucky 2-1 win against Syria in a Group C championship match on Friday .\"\n",
      "\n",
      "# The annotation instances that take place in the text above are listed here\n",
      "result = [\n",
      "    Location(span=\"Japan\"),\n",
      "    Miscellaneous(span=\"Asian Cup\"),\n",
      "    Location(span=\"Syria\"),\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6165c0d",
   "metadata": {},
   "source": [
    "## Prepare model inputs\n",
    "\n",
    "We remove everything after `result =` to run inference with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "19eabf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt, _ = text.split(\"result =\")\n",
    "prompt = prompt + \"result =\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f13c79d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = tokenizer(prompt, add_special_tokens=True, return_tensors=\"pt\")\n",
    "model_input[\"input_ids\"] = model_input[\"input_ids\"][:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6718528",
   "metadata": {},
   "source": [
    "## Run GoLLIE\n",
    "\n",
    "We generate the predictions using GoLLIE. \n",
    "\n",
    "We use `num_beams=1` and `do_sample=False` in our exmperiments. But feel free to experiment 😊\n",
    "\n",
    "- If you are running the model in CPU, this cell will take ~1 minute\n",
    "- If you are running the model in CUDA, this cell will take <10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b6f95263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 22s, sys: 15.9 s, total: 15min 37s\n",
      "Wall time: 47.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_ouput = model.generate(\n",
    "    input_ids=model_input.input_ids.to(model.device),\n",
    "    max_new_tokens=128,\n",
    "    do_sample=False,\n",
    "    min_new_tokens=0,\n",
    "    num_beams=1,\n",
    "    num_return_sequences=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f4a2a",
   "metadata": {},
   "source": [
    "### Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "31808b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 0\n",
      "[\n",
      "    Location(span=\"Japan\"),\n",
      "    Miscellaneous(span=\"Asian Cup\"),\n",
      "    Location(span=\"Syria\"),\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for y, x in enumerate(model_ouput):\n",
    "    print(f\"Answer {y}\")\n",
    "    print(tokenizer.decode(x,skip_special_tokens=True).split(\"result = \")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e2013f",
   "metadata": {},
   "source": [
    "## Parse the output\n",
    "\n",
    "The output is a Python module, we can execute it to parse the results and get a list with the annotations 🤯\n",
    "\n",
    "We define the AnnotationList class to parse the output with a single line of code. The `AnnotationList.from_output` function filters any label that we did not define (hallucinations) to prevent getting an `undefined class` error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5d66fb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Location(span='Japan'), Miscellaneous(span='Asian Cup'), Location(span='Syria')]\n"
     ]
    }
   ],
   "source": [
    "result = AnnotationList.from_output(tokenizer.decode(model_ouput[0],skip_special_tokens=True).split(\"result = \")[-1],task_module=\"guidelines\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27586bd8",
   "metadata": {},
   "source": [
    "Labels are an instance of the defined classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bd039309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guidelines.Location"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2703325b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Japan'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].span"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c52537",
   "metadata": {},
   "source": [
    "# Evaluate the result\n",
    "\n",
    "Finally, we will evaluate the outputs from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715535b7",
   "metadata": {},
   "source": [
    "First, we define an Scorer, for Named Entity Recognition, we will use the `SpanScorer` class.\n",
    "\n",
    "We need to define the valid_types for the scorer, which will be the labels that we have defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d44e1f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tasks.utils_scorer import SpanScorer\n",
    "\n",
    "class CoNLL03EntityScorer(SpanScorer):\n",
    "    \"\"\"CoNLL03 Entity identification and classification scorer.\"\"\"\n",
    "\n",
    "    valid_types: List[Type] = ENTITY_DEFINITIONS\n",
    "\n",
    "    def __call__(self, reference: List[Entity], predictions: List[Entity]) -> Dict[str, Dict[str, float]]:\n",
    "        output = super().__call__(reference, predictions)\n",
    "        return {\"entities\": output[\"spans\"]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9907289",
   "metadata": {},
   "source": [
    "### Instanciate the scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = CoNLL03EntityScorer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb11ce1",
   "metadata": {},
   "source": [
    "### Compute F1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "da72e844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': {'precision': 1.0,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 1.0,\n",
       "  'class_scores': {'Location': {'tp': 2,\n",
       "    'total_pos': 2,\n",
       "    'total_pre': 2,\n",
       "    'precision': 1.0,\n",
       "    'recall': 1.0,\n",
       "    'f1-score': 1.0},\n",
       "   'Miscellaneous': {'tp': 1,\n",
       "    'total_pos': 1,\n",
       "    'total_pre': 1,\n",
       "    'precision': 1.0,\n",
       "    'recall': 1.0,\n",
       "    'f1-score': 1.0}}}}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer(reference=[gold],predictions=[result])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collie",
   "language": "python",
   "name": "collie"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
